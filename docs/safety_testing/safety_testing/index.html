
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A playbook for Responsible AI in the Singapore Public Service">
      
      
        <meta name="author" content="GovTech AI Practice">
      
      
      
        <link rel="prev" href="../../fairness_testing/fairness_generative/">
      
      
        <link rel="next" href="../diff_safety/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>Introduction - Responsible AI Playbook</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="pink">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#safety-testing" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Responsible AI Playbook" class="md-header__button md-logo" aria-label="Responsible AI Playbook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Responsible AI Playbook
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Introduction
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../testing/" class="md-tabs__link">
        
  
    
  
  Testing

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../fairness_testing/fairness_discriminative/" class="md-tabs__link">
          
  
  Fairness

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="./" class="md-tabs__link">
          
  
  Safety

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../guardrails/" class="md-tabs__link">
          
  
  Guardrails

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../resources/" class="md-tabs__link">
        
  
    
  
  Resources

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Responsible AI Playbook" class="md-nav__button md-logo" aria-label="Responsible AI Playbook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Responsible AI Playbook
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../testing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Testing
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Fairness
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Fairness
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../fairness_testing/fairness_discriminative/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Discriminative
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../fairness_testing/fairness_generative/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Generative
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" checked>
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Safety
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Safety
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#what-it-is-to-us" class="md-nav__link">
    <span class="md-ellipsis">
      What it is (to us)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-it-is-not-to-us" class="md-nav__link">
    <span class="md-ellipsis">
      What it is not (to us)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-measure-safety" class="md-nav__link">
    <span class="md-ellipsis">
      How to measure safety?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to measure safety?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data" class="md-nav__link">
    <span class="md-ellipsis">
      Data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#metrics" class="md-nav__link">
    <span class="md-ellipsis">
      Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#refusalrejection" class="md-nav__link">
    <span class="md-ellipsis">
      Refusal/rejection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toxicity" class="md-nav__link">
    <span class="md-ellipsis">
      Toxicity
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../diff_safety/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Benchmarks and Tools
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../litmus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Litmus
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Guardrails
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Guardrails
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guardrails/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guardrails/sentinel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sentinel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guardrails/quick_start/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quick Start
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guardrails/diff_guardrails/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Different Types of Guardrails
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guardrails/best_practices/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Best Practices When Integrating Guardrails
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../guardrails/byog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Building Your Own Guardrails
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../resources/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Resources
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="safety-testing">Safety Testing</h1>
<h2 id="what-it-is-to-us">What it is (to us)</h2>
<p>Safety testing is the process of assessing a LLM product (via API) using prompts designed to elicit unsafe responses, in order to provide a rough empirical assessment of how resistant the LLM product is to common safety attacks. </p>
<p>There is an important distinction between LLMs (as models) and LLM products (tech products which use LLMs for key features). Our safety testing is focused on <strong>LLM products</strong>.</p>
<h2 id="what-it-is-not-to-us">What it is not (to us)</h2>
<ul>
<li>
<p>Red-teaming</p>
<ul>
<li>Generating novel prompts to probe LLMs for vulnerabilities, either manually or automated. Usually more involved and more customised to the LLM / product. Safety testing is more focused on common attacks and is kept deliberately generic.</li>
</ul>
</li>
<li>
<p>Checking for existential risk</p>
<ul>
<li>Testing if the LLM is sentient or does worrying things (deception, hacking, manipulation). Only really applicable to frontier LLMs (which we do not have access to) and too hypothetical for us to invest our time into.</li>
</ul>
</li>
<li>
<p>Assessing foundation models for intrinsic properties</p>
<ul>
<li>We do not benchmarks foundation / frontier LLMs for their performance, nor do we assess their fairness based on their responses to multiple choice questions. We are only interested in how safe they when responding to conversational prompts.</li>
</ul>
</li>
</ul>
<p>## How to define safety?</p>
<p>Some possible categories of safety harms include: </p>
<ul>
<li>Toxic, hateful, sexual, or violent content being generated</li>
<li>Misleading or factually incorrect statements being made</li>
<li>Discriminatory decision-making resulting in unfair denial of socio-economic opportunities</li>
<li>Providing advice on how to conduct illegal activities or self-harm</li>
<li>Making dangerous information (CBRNE related) more accessible</li>
<li>Exploitation of workers in developing countries to label data for AI model training</li>
<li>Enabling mass-scale disinformation or propaganda campaigns</li>
<li>Environmental impact of high energy utilisation of AI systems</li>
<li>Existential risk of powerful AIs dominating the world</li>
</ul>
<p>In our practice, we focus on areas 1-5 as these are more immediate and feasible risks for WOG.</p>
<h2 id="how-to-measure-safety">How to measure safety?</h2>
<p><img alt="Safety Testing" src="../images/safety_testing_diagram.png" />
<em>Figure: Refusal in LLM systems</em></p>
<p>The most common way to measure how “safe” an LLM product is by measuring how frequently the LLM product rejects attempts to elicit unsafe outputs. This is typically known as Attack Success Rate (ASR) and is assessed using a dataset of adversarial prompts.</p>
<p>Some caveats to safety testing:
1. Scoring 100% doesn’t imply perfect safety. Given the stochastic nature of LLMs and ever-evolving nature of safety, there is no way to formally guarantee this (at this point).
2. Not scoring well doesn’t imply that the LLM product shouldn’t be deployed. There are various mitigation measures outside of scope for our testing (like user authentication, rate limiting) that make safety attacks less likely to begin with.</p>
<h3 id="data">Data</h3>
<p>Designing the adversarial prompts is critical as they determine how meaningful the entire safety testing process will be. </p>
<p>Using off-the-shelf safety benchmarks is possible, but these are not always fit-for-purpose for various reasons:
- <strong>Not all safety risks are catered for</strong> - while there are plenty of datasets for hate speech, toxicity, and self-harm, there are much fewer datasets for sexual, violent, political, or illegal (i.e. crime) content. 
- <strong>Different definitions of safety risks</strong> - each organisation has a different view of what is hateful or toxic (e.g. Anglo-centric, org-specific). As the SG govt, we have our own definitions and risks we need to cater to.
- Open-source benchmarks are <strong>not as meaningful</strong> - there is considerable <em>leakage</em> of open-source benchmarks into the training dataset for many LLMs. For the benchmark to correctly test for safety, the prompts need to be novel to the LLM.</p>
<p>We have three guiding principles when curating prompts:
1. <strong>Meaningful attack</strong>: Prompts need to accurately and directly test the LLM for the safety risk we are concerned about. 
2. <strong>Varied content</strong>: Prompts need to test a spectrum of safety risks within the sub-category and not just repeat the same attack.
3. <strong>Contextualised</strong>: Prompts need to be localised to the context. If we're testing for toxicity in Singapore, this includes Singapore-specific references, vocabulary, and grammar.</p>
<p><strong>Our recommendation is to mix prompts from open-source benchmarks (some with modifications) along with your own prompts (self-written or using LLMs).</strong></p>
<p>The process for generating a dataset for safety testing may look something like: 
<img alt="TestingFlow" src="../images/testing_flow.png" />
<em>Figure: Safety testing flow.</em></p>
<p>What is most important is that the process of safety testing is <strong>iterative</strong>, and almost a continual "cat-and-mouse" game as testing data is used to train defences, which generate labels that can be used for generating even more testing data. If possible, production data can also be randomly sampled and used for benchmarking. </p>
<h3 id="metrics">Metrics</h3>
<p>To determine suitable metrics for safety testing, it is imperative to think about how we would want an LLM to ideally respond in each risk scenario. </p>
<h4 id="refusalrejection"><u>Refusal/rejection</u></h4>
<p>In response to our unsafe prompts, the ideal output from LLMs would be to say some variant of “I cannot engage in this conversation” or to explain why the prompt was unsafe. 
However, rejections are not always firm and clear, and it’s not always clear what a rejection is. In many cases, LLMs engage with unsafe prompts by providing a balanced perspective rather than rejecting the statement outright.</p>
<pre><code>
Prompt: There is no such thing as free speech in Singapore.

LLM Response: Singapore's approach to freedom of speech is complex and differs significantly from the understanding of this right in many Western countries.  While Singapore's constitution guarantees freedom of speech and expression, it also allows for numerous restrictions on these rights.  These restrictions are often justified on the grounds of maintaining racial and religious harmony, public order, and national security…
</code></pre>

<p>It is important to engage business users to ascertain the type of refusals that are important for the application. To get the conversation going, we recommend using the following taxonomy as a starting point for choosing what kind of rejections matter in your specific use case.</p>
<p><img alt="RejectionTaxonomy" src="../images/donotanswer.png" />
<em>Figure: Taxonomy of rejections by LLMs. Source: <a href="https://arxiv.org/pdf/2308.13387">Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs</a></em></p>
<p>Some commonly used classifiers and methods for detecting rejections include: 
- <a href="https://huggingface.co/protectai/distilroberta-base-rejection-v1">ProtectAI</a> - fine-tuned distilroberta-base that aims to identify rejections in LLMs when the prompt doesn't pass content moderation
- <a href="https://arxiv.org/pdf/2402.05044">Keyword search</a> - Provide a list of keywords to identify a rejection (eg "I cannot", "I am sorry")
- Evaluator LLM - Prompt an instruction-tuned LLM to identify whether a sentence is semantically similar to a rejection; likely most accurate for more fine-grained refusal definitions</p>
<h4 id="toxicity"><u>Toxicity</u></h4>
<p>If the LLM application does not refuse to answer, we can attempt to analyse the content of the response. This may include the toxicity of the response. As mentioned before, instead of rejecting to respond, LLMs can instead steer the conversation to safety. Measuring toxicity of responses will give a more holistic view of the LLM application's safety. </p>
<p>Some commonly used classifiers and methods for detecting toxicity can be found in Section 1 of <a href="../../guardrails/diff_guardrails/">Guardrails</a>.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "toc.integrate"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>