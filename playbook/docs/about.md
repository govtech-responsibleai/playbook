# About this playbook 

## Who is this for 

This playbook aims to provide resources, recommendations and technical guides to deploying AI responsibly in your applications. It is specifically targeted at **application developers**, who are excited to launch AI products, but are concerned of the risks and may not now how to begin mitigating these risks. This playbook aims to reduce the effort required by developers to survey and curate the extensive landscape of AI safety resources online, and provide an **practical starting point** to guard your applications against basic risks. In short, this playbook aims to enable you to **ship fast and safely**. 

## How to best make use of this 

This playbook will be continually updated and maintained, at least on a per-quarterly basis. When new tools or resources are available, we aim to assess them quickly and include them in the playbook where applicable. If you're new to AI safety, our recommendation is to start with a few most important risk categories for testing and guardrails; before moving on to more advanced and extensive testing as the product matures. 

For more customised solutions, feel free to reach out to our team at [GovTech's AI Practice (Responsible AI)](mailto:jessica_foo@tech.gov.sg) for a more in-depth discussion. 

## About us 
To be filled in

## Contributions

We welcome contributions to this playbook as we work together to ensure Responsible AI in government. This playbook is meant to be a living document as we adapt to new insights, real-world challenges, and emerging practices. Our goal is to create a practical resource that serves the diverse needs of the public sector and remains grounded in the realities of deployment and implementation. 

If you would like to contribute, please raise a pull request and we will review it accordingly. Thank you. 

