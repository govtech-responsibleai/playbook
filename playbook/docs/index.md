# Responsible AI Playbook

![](images/responsibleai.png)

## About this playbook

Our aim is to help people understand and apply Responsible AI from a technical perspective. We do so in three ways:  

1. Clear and detailed **explanations for key concepts** in Responsible AI (such as safety, fairness, and interpretability)  
2. Easy-to-follow and actionable **recommendations for deploying AI responsibly** for your applications  
3. **Curated resources and papers** to dive deeper into various aspects of Responsible AI  

Our hope is for our playbook to help you to **quickly grasp the entire landscape** of papers, guides, tools, and methodologies relating to Responsible AI, provide a **practical starting point** to guard your AI applications against basic risks, and thus enabling you to **ship fast and responsibly**.

## Our target audience

This playbook is primarily meant for **application developers** working in the Singapore government, especially those who are excited to develop and launch AI products but are concerned about managing safety or bias concerns about AI. However, this playbook will also be helpful to **product managers**, **CIO teams**, and even **policy officers**, as long as you have some foundational understanding of key AI concepts and are keen to learn more about Responsible AI.

Although this playbook is written with the Singapore government's context in mind, most of the explanations and recommendations in this playbook should be applicable to anyone building AI applications. After all, building safe, fair, and responsible AI applications is a common goal for many organisations. 

## About us 

To be filled in

## How to best make use of this 

To be edited

Given the pace of development in the AI space, we aim to continually update this playbook on a quarterly basis. When new tools or resources are available, we hope to quickly assess them and include them in the playbook. 

If you're new to AI safety, our recommendation is to start with a few most important risk categories for testing and guardrails; before moving on to more advanced and extensive testing as the product matures. 

For more customised solutions, feel free to reach out to our team at [GovTech's AI Practice (Responsible AI)](mailto:jessica_foo@tech.gov.sg) for a more in-depth discussion. 


## Contributions

We welcome contributions to this playbook as we work together to ensure Responsible AI in government. This playbook is meant to be a living document as we adapt to new insights, real-world challenges, and emerging practices. Our goal is to create a practical resource that serves the diverse needs of the public sector and remains grounded in the realities of deployment and implementation. 

If you would like to contribute, please raise a pull request and we will review it accordingly. Thank you. 
